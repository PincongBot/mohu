{"type":"article_comment","id":11426,"parentType":"article","parentId":1981,"uid":16,"contents":"<blockquote>[quote] </blockquote>能否自动把.jpg或者.png之类扩展名后面一堆删掉并把前面prev...[/quote]<br>\n<br>\nimport re<br>\nimport urllib<br>\nimport urllib.request<br>\nfrom bs4 import BeautifulSoup<br>\n<br>\ndef safe_url(link):<br>\nlink = link.replace('preview','i')<br>\npos = link.find('?')<br>\ntoken = link[pos:len(link)]<br>\nreturn link.replace(token,'')<br>\n<br>\ndef is_valid(link):<br>\n return 'redditstatic' not in link<br>\n<br>\ndef find(url):<br>\n<br>\nreq = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})<br>\npage = urllib.request.urlopen(req).read()<br>\nsoup = BeautifulSoup(page,'html.parser')<br>\ntitle = soup.title.string<br>\nprint(title)<br>\ntaglist = soup.find_all(['p','img'])<br>\ntext_string = ''<br>\ntarget_str = '[/img]'<br>\nfor tr in taglist:<br>\nif tr.text:<br>\ntext_string += tr.text<br>\ntext_string += '\\n'<br>\nelse:<br>\ntext_string += ''<br>\ntext_string += safe_url(tr['src'])<br>\ntext_string += '\\n'<br>\n<br>\npos = text_string.rfind(target_str)<br>\n<br>\ntext_string = text_string[0:pos + len(target_str)]<br>\ntext_string = text_string.split('\\n')<br>\ntext_string = filter(is_valid, text_string)<br>\ntext_string = '\\n'.join(text_string)<br>\nprint(text_string)<br>\n<br>\n#url = 'http://127.0.0.1/phptest/reddit.html'<br>\n#find(url)","date":"2020-05-10","agreeCount":3,"discussionCount":0}