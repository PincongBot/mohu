{"type":"article_comment","id":11426,"parentType":"article","parentId":1981,"uid":16,"contents":"<blockquote>[quote] </blockquote>能否自动把.jpg或者.png之类扩展名后面一堆删掉并把前面prev...[/quote]<br>\n<br>\nimport re<br>\nimport urllib<br>\nimport urllib.request<br>\nfrom bs4 import BeautifulSoup<br>\n<br>\ndef safe_url(link):<br>\n  link = link.replace('preview','i')<br>\n  pos = link.find('?')<br>\n  token = link[pos:len(link)]<br>\n  return link.replace(token,'')<br>\n<br>\ndef is_valid(link):<br>\n    return 'redditstatic' not in link<br>\n<br>\ndef find(url):<br>\n   <br>\n    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})<br>\n    page = urllib.request.urlopen(req).read()<br>\n    soup = BeautifulSoup(page,'html.parser')<br>\n    title = soup.title.string<br>\n    print(title)<br>\n    taglist = soup.find_all(['p','img'])<br>\n    text_string = ''<br>\n    target_str = '[/img]'<br>\n    for tr in taglist:<br>\n        if tr.text:<br>\n            text_string += tr.text<br>\n            text_string += '\\n'<br>\n        else:<br>\n            text_string += ''<br>\n            text_string += safe_url(tr['src'])<br>\n            text_string += '\\n'<br>\n           <br>\n    pos = text_string.rfind(target_str)<br>\n   <br>\n    text_string = text_string[0:pos + len(target_str)]<br>\n    text_string = text_string.split('\\n')<br>\n    text_string = filter(is_valid, text_string)<br>\n    text_string = '\\n'.join(text_string)<br>\n    print(text_string)<br>\n<br>\n#url = 'http://127.0.0.1/phptest/reddit.html'<br>\n#find(url)","date":"2020-05-10","agreeCount":3,"discussionCount":0}